{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MitoRibo Bayesian inference to obtain timescale posteriors\n",
    "Author: Robert Ietswaart  \n",
    "Date: 20220205  \n",
    "License: BSD2.  \n",
    "Load modules j3dl and activate virtual environment using j4RNAdecay on O2.  \n",
    "Python v3.7.4\n",
    "\n",
    "Source: `Timescale_Bayes_20210615.ipynb`  \n",
    "For Erik's mito RNA kinetics project using mitoribo subcellular timelapse seq: Bayesian inference to get timescale posteriors based on Grand-Slam new to total RNA ratio (NTR) posteriors for individual genes on mitototal and mitoribosome fractions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "import seaborn as sns\n",
    "from scipy.integrate import quad, cumulative_trapezoid \n",
    "\n",
    "# from __init__ import __version__\n",
    "from __init__ import default_logger_format, default_date_format\n",
    "\n",
    "import new_total_ratio_jit as ntr\n",
    "import posteriors_jit as p\n",
    "\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "from numba.core import types\n",
    "from numba.typed import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "np.random.seed(12345)\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Run Bayesian timescale fitting on mitoribo subcellular timelapse seq')\n",
    "\n",
    "args = parser.parse_args(\"\")#EDIT: added \"\" as argument to run in ipynb instead of .py script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('/n','groups','churchman','ri23','RNAdecay','GS20220204')\n",
    "outpath = os.path.join('/n','groups','churchman','ri23','RNAdecay','Bayes20220204_mitoribo')\n",
    "\n",
    "# Add a logger specific to the project and processing stage\n",
    "logger = logging.getLogger('scTLseq_mitoribo')\n",
    "log_file = os.path.join(outpath,'LogErr', 'scTLseq_mitoribo_20220204.log')\n",
    "formatter = logging.Formatter(default_logger_format,\n",
    "                              datefmt=default_date_format)\n",
    "log_handler = logging.FileHandler(log_file)\n",
    "log_handler.setFormatter(formatter)\n",
    "logger.addHandler(log_handler)\n",
    "\n",
    "fracs = ['tot','mitoribo']\n",
    "fracs_model = {'tot': ['tot_fit'],\n",
    "               'mitoribo': ['mitoribo_fit']}\n",
    "frac_filename={'tot': '_tot_MTdsrRNA_t5MTMMinformed6_modeAll_PcMod3tot.tsv',\n",
    "                'mitoribo': '_IP_MTdsrRNA_t5MTMMinformed6_modeAll_PcMod4IP.tsv'}\n",
    "reps = ['TL8']\n",
    "background_id = {r: '1' for r in reps}\n",
    "time_mins = [0,15,30,60]\n",
    "time_measured = np.asarray(time_mins[1:])\n",
    "T_max = time_mins[-1] + 30 #only used for plotting continuous curves\n",
    "time_cont = pd.Series(range(0, T_max)) #only used for plotting continuous curves\n",
    "\n",
    "CI_para = ['alpha','beta']\n",
    "OUT_TYPES = [' Mean', ' MAP', ' 0.975 quantile', ' 0.025 quantile'] # \n",
    "#the CIs must match alpha/2 and 1-alpha/2 in get_post_ci()\n",
    "\n",
    "Timescales = ['T_mito_entry',\n",
    "              'T_deg']\n",
    "\n",
    "GS = dict()\n",
    "for r in reps:\n",
    "    for fr in fracs:\n",
    "        filename = r + frac_filename[fr]  \n",
    "        if os.path.exists(os.path.join(path, filename)):\n",
    "            GS[r+fr]= pd.read_csv(os.path.join(path, filename), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_grid = 1000 #to divide [k_bound_lo,k_bound_hi] interval\n",
    "k_bound_lo = 1e-4 #unit: min^-1: 1 per 7 days\n",
    "k_bound_hi = 1e4 #unit: min^-1: 1 per 6 ms, if too restrictive: increase to 1e6\n",
    "\n",
    "@jit(nb.float64(nb.float64, types.DictType(types.unicode_type, nb.float64[:])), \n",
    "     nopython=True)\n",
    "def post_mitototal(kD, NTR):\n",
    "    prob = 1\n",
    "    for i in range(time_measured.shape[0]):\n",
    "        t = time_measured[i]\n",
    "        lam = ntr.lam_total_one_step(kD, t)        \n",
    "        alpha_g_t = NTR['alpha'][i]\n",
    "        beta_g_t = NTR['beta'][i]\n",
    "        beta_pdf_g = p.beta_pdf(lam, alpha_g_t, beta_g_t)\n",
    "        prob = prob * beta_pdf_g * p.det_jac_mitototal(kD, t)\n",
    "    return prob   \n",
    "\n",
    "@jit(nb.float64(nb.float64, nb.float64, types.DictType(types.unicode_type, nb.float64[:])), \n",
    "     nopython=True)\n",
    "def post_mitoribo(kL, kD, NTR):\n",
    "    prob = 1\n",
    "    for i in range(time_measured.shape[0]):\n",
    "        t = time_measured[i]\n",
    "        lam = ntr.lam_ribo(kL, kD, t)       \n",
    "        alpha_g_t = NTR['alpha'][i]\n",
    "        beta_g_t = NTR['beta'][i]\n",
    "        beta_pdf_g = p.beta_pdf(lam, alpha_g_t, beta_g_t)\n",
    "        prob = prob * beta_pdf_g * p.det_jac_mitoribo_from_tot(kL, kD, t)\n",
    "    return prob  \n",
    "\n",
    "def get_conditional_dist(post, NTR, ci, nvar):\n",
    "    '''\n",
    "    Calculate the marginal posterior by integration over the previous rate with \n",
    "    ci as integration boundaries.\n",
    "    post: multivariate posterior\n",
    "    '''\n",
    "    def marg_dist(x, NTR):\n",
    "        return quad(post, ci[0][0], ci[0][1], args=(x, NTR), epsabs=1e-3)[0]\n",
    "    cond_dist = marg_dist\n",
    "#     logger.info('p_g_c_d1')\n",
    "    return cond_dist\n",
    "\n",
    "def get_post_norm_const(post, NTR):    \n",
    "    #integrate over small subdomains\n",
    "    omega = 0\n",
    "    omega_err = 0\n",
    "    for i in range(8):#if k_bound_lo and k_bound_hi: update 4 or 8\n",
    "        k_int_lo = k_bound_lo * 10**(i)#(2*i)#\n",
    "        k_int_hi = k_bound_lo * 10**(i+1)#(2*(i+1))#\n",
    "        try:\n",
    "            k_int, k_int_err = quad(post, k_int_lo, k_int_hi, args=(NTR), epsabs=1e-3)\n",
    "            logger.info('norm_const %f %f' % (k_int, k_int_err))\n",
    "            if np.isnan(k_int):\n",
    "                logger.warning('norm_err1: %f %f' % (k_int, k_int_err))\n",
    "                omega = np.nan\n",
    "                omega_err = np.nan\n",
    "                break\n",
    "        except (IndexError, KeyError, ZeroDivisionError):\n",
    "            logger.warning('norm_err2 %f %f' % (k_int, k_int_err))\n",
    "            omega = np.nan\n",
    "            omega_err = np.nan\n",
    "            break\n",
    "        omega += k_int\n",
    "        omega_err += k_int_err\n",
    "    \n",
    "    if omega == 0:\n",
    "        logger.warning('norm_err3: norm_const is zero, set to nan and abort')\n",
    "        omega = np.nan\n",
    "        omega_err = np.nan\n",
    "    return omega, omega_err\n",
    "    \n",
    "def get_post_mean(post, NTR, norm_const):\n",
    "    def integrand(x, ntr):#cannot be jitted bc it does not recognize function post\n",
    "        return x * post(x, ntr) / norm_const\n",
    "    \n",
    "    #integrate over small subdomains\n",
    "    k_mean = 0\n",
    "    k_mean_err = 0\n",
    "    for i in range(8):#if k_bound_lo and k_bound_hi: update 4 or 8\n",
    "        k_int_lo = k_bound_lo * 10**(i)#(2*i)#\n",
    "        k_int_hi = k_bound_lo * 10**(i+1)#(2*(i+1))#\n",
    "        try:\n",
    "            k_int, k_int_err = quad(integrand, k_int_lo, k_int_hi, args=(NTR), epsabs=1e-3)\n",
    "            logger.info('mean %f %f' % (k_int, k_int_err))\n",
    "            if np.isnan(k_int):\n",
    "                logger.warning('mean_err1 %f %f' % (k_int_lo, k_int_hi))\n",
    "                k_mean = np.nan\n",
    "                k_mean_err = np.nan\n",
    "                break\n",
    "        except (IndexError, KeyError, ZeroDivisionError):\n",
    "            logger.warning('mean_err2 %f %f' % (k_int_lo, k_int_hi))\n",
    "            k_mean = np.nan\n",
    "            k_mean_err = np.nan\n",
    "            break\n",
    "        k_mean += k_int\n",
    "        k_mean_err += k_int_err\n",
    "    \n",
    "    if k_mean == 0:\n",
    "        logger.warning('mean_err3: mean is zero, set to nan')\n",
    "        k_mean = np.nan\n",
    "        k_mean_err = np.nan\n",
    "    return k_mean, k_mean_err\n",
    "\n",
    "def get_post_ci(k_domain, post_grid):\n",
    "    alpha = 0.05\n",
    "    #CDF via cumulative trapezoid\n",
    "    cdf = cumulative_trapezoid(post_grid, k_domain, initial=0) \n",
    "    omega = max(cdf)\n",
    "    logger.info('omega %f' % omega)\n",
    "    cdf = cdf / omega #pdf was already normalized, but just in case, normalize cdf as well\n",
    "    \n",
    "    k_temp = k_domain[cdf <= (alpha / 2)]\n",
    "    if k_temp.size:\n",
    "        ci_lo = max(k_temp)\n",
    "    else:\n",
    "        ci_lo = k_domain[0]\n",
    "    k_temp = k_domain[cdf >= (1 - alpha / 2)]\n",
    "    if k_temp.size:\n",
    "        ci_hi = min(k_temp)\n",
    "    else: \n",
    "        N_domain = len(k_domain)\n",
    "        ci_hi = k_domain[N_domain -1]\n",
    "    return ci_lo, ci_hi\n",
    "\n",
    "def get_estimates_from_post(post, NTR, N_var, ci_k_prev=None):\n",
    "    '''\n",
    "    post : possibly multivariate posterior (function). If N_var > 1, the marginal\n",
    "           distribution of the unknown rate, conditioned on ci_k_prev, will replace this\n",
    "           multivariate posterior.\n",
    "    N_var : number of rate arguments of the posterior.\n",
    "    ci_k_prev : credible intervals of CIs of the previously fitted rates (list of tuples).\n",
    "    ''' \n",
    "    if N_var > 1:\n",
    "        post_new = get_conditional_dist(post, NTR, ci_k_prev, N_var)\n",
    "        post = post_new     \n",
    "    logger.info('g_e_f_p0')\n",
    "\n",
    "    #determine normalization constant for (marginal) posterior probability distribution\n",
    "    norm_const, err = get_post_norm_const(post, NTR)\n",
    "    logger.info('norm_constant %f %f' % (norm_const, err))\n",
    "    logger.info('g_e_f_p1')  \n",
    "    \n",
    "    if np.isfinite(norm_const):\n",
    "        #Initialize the prior domain of rate\n",
    "        k_domain = np.geomspace(k_bound_lo, k_bound_hi, num=N_grid)\n",
    "        post_grid = np.empty(N_grid)\n",
    "        for i in range(N_grid):\n",
    "            post_grid[i] = post(k_domain[i], NTR) #evaluate posterior in a grid to get k_map and CIs\n",
    "        post_grid = post_grid / norm_const\n",
    "        logger.info('g_e_f_p2') \n",
    "\n",
    "        mean_k, mean_k_err = get_post_mean(post, NTR, norm_const)\n",
    "        logger.info('g_e_f_p3')  \n",
    "        map_k = k_domain[np.argmax(post_grid)]\n",
    "        logger.info('g_e_f_p4')  \n",
    "\n",
    "        ci_lo, ci_hi = get_post_ci(k_domain, post_grid)\n",
    "        logger.info('g_e_f_p5')\n",
    "    else:\n",
    "        [mean_k, map_k, ci_lo, ci_hi] = [np.nan for i in range(4)]\n",
    "        \n",
    "    return np.asarray([mean_k, map_k, ci_lo, ci_hi]) #, post_grid]) #include post_grid for plotting post dist\n",
    "\n",
    "@jit(nb.float64[:](types.unicode_type, types.unicode_type,\n",
    "                types.DictType(types.unicode_type, nb.float64[:]), types.unicode_type), nopython=True) \n",
    "def get_model_pred(rr, frm, k, e_type):\n",
    "    N_time = time_measured.shape[0]\n",
    "    NTR_model = np.empty(N_time) \n",
    "    if e_type == ' Mean':\n",
    "        idx = 0\n",
    "    else:#'MAP'\n",
    "        idx = 1\n",
    "        \n",
    "    if frm == 'tot_fit':\n",
    "        for i in range(N_time):\n",
    "            NTR_model[i] = ntr.lam_total_one_step(k[rr+'T_deg'][idx], \n",
    "                                                  time_measured[i])  \n",
    "    elif frm == 'mitoribo_fit':\n",
    "        for i in range(N_time):\n",
    "            NTR_model[i] = ntr.lam_ribo(k[rr+'T_mito_entry'][idx], \n",
    "                                        k[rr+'T_deg'][idx], \n",
    "                                        time_measured[i])\n",
    "    return NTR_model\n",
    "\n",
    "\n",
    "@jit(nb.float64(nb.float64[:], nb.float64[:]), nopython=True) \n",
    "def get_chi2_jit(ntr_meas, ntr_model):\n",
    "    eps = 1e-16\n",
    "    chi2 = 0\n",
    "    for i in range(ntr_meas.shape[0]):\n",
    "        chi2 = chi2 + (ntr_model[i]-ntr_meas[i])**(2) / (ntr_model[i]+eps)\n",
    "    return chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Write to file genes that have sufficient data to estimate timescales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_w_rates = dict()\n",
    "for r in reps:\n",
    "    for fr in fracs:\n",
    "        if fr == 'tot':\n",
    "            genes_w_rates[r] = set(GS[r+fr]['Gene'])\n",
    "            logger.info('%s %s %s' % (r, fr, len(genes_w_rates[r])))\n",
    "        elif fr in ['mitoribo']:\n",
    "            genes_w_rates[r] = genes_w_rates[r].union(GS[r+fr]['Gene'])\n",
    "            logger.info('%s %s %s' % (r, fr, len(genes_w_rates[r])))\n",
    "if len(reps) > 1:\n",
    "    for r in reps[1:]:\n",
    "        genes_w_rates = genes_w_rates[reps[0]].union(genes_w_rates[r])\n",
    "else:\n",
    "    genes_w_rates = genes_w_rates[reps[0]]\n",
    "genes_w_rates = sorted(list(genes_w_rates))\n",
    "logger.info('total number of genes: union of (if > 1) biological replicates: %d' % len(genes_w_rates))\n",
    "\n",
    "filename = 'genes_w_rates.csv'\n",
    "genes_df = pd.Series(genes_w_rates)\n",
    "# genes_df.to_csv(os.path.join(outpath, filename), sep='\\t',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info('Run model parameter fitting for all genes')\n",
    "\n",
    "#initialize the fit dictionary with columns\n",
    "fits = dict()\n",
    "fits['Gene'] = []\n",
    "fits['Symbol'] = []\n",
    "for r in reps:\n",
    "    for timescale in Timescales:\n",
    "        for suf in OUT_TYPES:\n",
    "            fits[r+'.'+timescale+suf] = []\n",
    "\n",
    "for r in reps:\n",
    "    for fr in fracs:\n",
    "            for frm in fracs_model[fr]:\n",
    "                for estimate_type in OUT_TYPES[:2]:\n",
    "                    fits[r+'.'+frm+estimate_type+'.chi2'] = []\n",
    "\n",
    "for ensid in genes_w_rates:#[:1]:\n",
    "    logger.info(ensid)\n",
    "    symbol = ''\n",
    "    #initialize k_fit per gene\n",
    "    k_fit = Dict.empty(key_type=types.unicode_type,\n",
    "                value_type=types.float64[:])\n",
    "    for r in reps:\n",
    "        for timescale in Timescales:\n",
    "            k_fit[r + timescale] = np.asarray([np.nan for out in OUT_TYPES])\n",
    "    \n",
    "    for r in reps:  \n",
    "        for fr in fracs:\n",
    "                try:\n",
    "                    \n",
    "                    # The Dict.empty() constructs a typed dictionary.\n",
    "                    # The key and value typed must be explicitly declared.\n",
    "                    AB = Dict.empty(key_type=types.unicode_type,\n",
    "                                    value_type=types.float64[:],)\n",
    "                    ABORT = False\n",
    "                         \n",
    "                    gene_idx = GS[r+fr][GS[r+fr]['Gene']==ensid].index[0]\n",
    "                    symbol = GS[r+fr]['Symbol'][gene_idx]\n",
    "                    for ab in CI_para:\n",
    "                        gs_ab_times = [r+'_'+str(t)+'m '+ab for t in time_mins[1:]]\n",
    "                        AB[ab] = np.asarray(GS[r+fr].loc[gene_idx, gs_ab_times], dtype='float64')\n",
    "                        if np.prod(np.isfinite(AB[ab])) == 0:\n",
    "                            logger.warning('%s %s: abort because AB contains nonfinite data' % (r,fr))\n",
    "                            ABORT = True\n",
    "                            break\n",
    "\n",
    "                    if not ABORT:\n",
    "                        for frm in fracs_model[fr]:\n",
    "                            logger.info('fitting rate for %s %s %s' % (r, fr, frm))\n",
    "                            try:                        \n",
    "                                if frm == 'tot_fit':\n",
    "                                    k_fit[r+'T_deg'] = get_estimates_from_post(post_mitototal, AB, 1)   \n",
    "                                elif frm == 'mitoribo_fit' and \\\n",
    "                                    sum(np.isnan(k_fit[r + 'T_deg'][2:])) == 0:\n",
    "                                    k_fit[r+'T_mito_entry'] = get_estimates_from_post(post_mitoribo, AB, 2, \n",
    "                                                                        [k_fit[r+'T_deg'][2:4]])\n",
    "    \n",
    "                            except (IndexError, KeyError, ZeroDivisionError):\n",
    "                                logger.warning('except error, so nan rates')\n",
    "\n",
    "                except (IndexError, KeyError, ZeroDivisionError):\n",
    "                    logger.warning('%s %s: no data, so nan rates' % (r, fr))\n",
    "\n",
    "    #append timescales (1/rate) in fits dictionary            \n",
    "    if r in reps:\n",
    "        for timescale in Timescales:\n",
    "            for i, out in enumerate(OUT_TYPES):\n",
    "                fits[r+'.'+timescale+out].append((k_fit[r+timescale][i])**(-1))\n",
    "\n",
    "    #Get predictions\n",
    "    logger.info('get model fit chi2')\n",
    "    if r in reps:\n",
    "        for fr in fracs:           \n",
    "            for estimate_type in OUT_TYPES[:2]:\n",
    "                gs_times = [r+'_'+str(t)+'m'+estimate_type for t in time_mins[1:]]\n",
    "#                 logger.info(gs_times)\n",
    "                try:                        \n",
    "                    gene_idx = GS[r+fr][GS[r+fr]['Gene']==ensid].index[0]\n",
    "                    NTR = np.asarray(GS[r+fr].loc[gene_idx, gs_times], dtype='float64')\n",
    "    #                 logger.warning(NTR)\n",
    "                    for frm in fracs_model[fr]:                 \n",
    "                        NTR_model = get_model_pred(r, frm, k_fit, estimate_type)\n",
    "                        chi2 = get_chi2_jit(NTR, NTR_model)\n",
    "                        fits[r+'.'+frm+estimate_type+'.chi2'].append(chi2)  \n",
    "                except (IndexError, KeyError):\n",
    "                    for frm in fracs_model[fr]:\n",
    "                        fits[r+'.'+frm+estimate_type+'.chi2'].append(np.nan)\n",
    "                    \n",
    "    fits['Gene'].append(ensid)    \n",
    "    fits['Symbol'].append(symbol)\n",
    "\n",
    "filename = 'Bayes20220206_mitoribo_fit_timescales.tsv' \n",
    "logger.info('Write results to file %s' % filename)\n",
    "fits_df = pd.DataFrame(fits)\n",
    "# fits_df.to_csv(os.path.join(outpath, filename), sep='\\t',index=False)\n",
    "\n",
    "logger.info('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNFINISHED BELOW: visualization for individual genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = 'Hnrnpd'#'Nfat5'#'Lsr'#'Stard3'#'Txnrd3'#'Bysl'#'Alyref' #'Narf'#'Apoh' #'Tbx2'#'Apoh'#'Gapdh' # 'Myc' #'Gnai3' # #'Klf4' #'Tfam' ##'Alyref' #'Tfam' #'Vps50' #  # #'Uba3' ## ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(gene)\n",
    "\n",
    "k_fit = dict()\n",
    "for r in reps:   \n",
    "    for fr in fracs:\n",
    "#         if r+fr+'top1000' in GS.keys():\n",
    "            logger.info('%s %s' % (r, fr))\n",
    "\n",
    "            # The Dict.empty() constructs a typed dictionary.\n",
    "            # The key and value typed must be explicitly declared.\n",
    "            AB = Dict.empty(key_type=types.unicode_type,\n",
    "                             value_type=types.float64[:],)\n",
    "            ABORT = False\n",
    "            \n",
    "            try:\n",
    "                    gene_idx = GS[r+fr][GS[r+fr]['Symbol']==gene].index[0]\n",
    "                    for ab in CI_para:\n",
    "                        gs_times = [r+t+'.'+ab for t in time_id[1:]]\n",
    "                        AB[ab] = np.asarray(GS[r+fr].loc[gene_idx,gs_times], dtype='float64')\n",
    "                        logger.info('AB %s %s' % (ab, AB[ab]))\n",
    "                        if np.prod(np.isfinite(AB[tc+ab])) == 0:\n",
    "                            logger.warning('Abort because AB contains nonfinite data')\n",
    "                            ABORT = True\n",
    "                            break\n",
    "                    if ABORT:\n",
    "                        break\n",
    "\n",
    "                if not ABORT:\n",
    "                    for frm in fracs_model[fr]:\n",
    "                        logger.info('%s %s %s' % (r, fr, frm))\n",
    "#Change to:\n",
    "#                         'tot': ['tot_fit'],\n",
    "#                'mitoribo': ['mitoribo_fit']\n",
    "                        \n",
    "                        if frm == 'tot_fit':\n",
    "                            k_fit[red_r[r]+frm] = get_estimates_from_post(post_mitototal, AB, 1)   \n",
    "                        elif frm == 'nucpl_fit':\n",
    "                            k_fit[red_r[r]+frm] = get_estimates_from_post(post_nucpl, TC_TYPES_gene, AB, 2, \n",
    "                                                                          [k_fit[red_r[r]+'chr_fit'][2:4]])\n",
    "                        elif frm == 'nuc_fit':\n",
    "                            k_fit[red_r[r]+frm] = get_estimates_from_post(post_nuc, TC_TYPES_gene, AB, 1)\n",
    "                        elif frm == 'cyto_fit_from_chr_nucpl':\n",
    "                            k_fit[red_r[r]+frm] = get_estimates_from_post(post_cyto_from_chr, TC_TYPES_gene, AB, 3, \n",
    "                                                                          [k_fit[red_r[r]+'chr_fit'][2:4],\n",
    "                                                                           k_fit[red_r[r]+'nucpl_fit'][2:4]])\n",
    "                        elif frm == 'cyto_fit_from_nuc':\n",
    "                            k_fit[red_r[r]+frm] = get_estimates_from_post(post_cyto_from_nuc, TC_TYPES_gene, AB, 2, \n",
    "                                                                          [k_fit[red_r[r]+'nuc_fit'][2:4]])\n",
    "                        elif frm == 'poly_fit_from_chr_nucpl':\n",
    "                            k_fit[red_r[r]+frm] = get_estimates_from_post(post_poly_from_chr, TC_TYPES_gene, AB, 4, \n",
    "                                                                 [k_fit[red_r[r]+'chr_fit'][2:4], \n",
    "                                                                  k_fit[red_r[r]+'nucpl_fit'][2:4], \n",
    "                                                                  k_fit[red_r[r]+'cyto_fit_from_chr_nucpl'][2:4]])\n",
    "        #                     continue\n",
    "                        elif frm == 'poly_fit_from_nuc':\n",
    "                            k_fit[red_r[r]+frm] = get_estimates_from_post(post_poly_from_nuc, TC_TYPES_gene, AB, 3, \n",
    "                                                                          [k_fit[red_r[r]+'nuc_fit'][2:4], \n",
    "                                                                           k_fit[red_r[r]+'cyto_fit_from_nuc'][2:4]])\n",
    "        #                     continue\n",
    "                        elif frm == 'tot_fit':\n",
    "                            k_fit[red_r[r]+frm] = get_estimates_from_post(post_tot, TC_TYPES_gene, AB, 1)\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        logger.info('time_fit %s %s %s \\n' % (red_r[r], frm, [1/k for k in k_fit[red_r[r]+frm][:4]]))\n",
    "                else:\n",
    "                    for frm in fracs_model[fr]:\n",
    "                        k_fit[red_r[r]+frm] = [np.nan for i in range(5)]\n",
    "            except (IndexError, KeyError, ZeroDivisionError):\n",
    "                logger.warning('no data, so no nan rates')\n",
    "                for frm in fracs_model[fr]:\n",
    "                    k_fit[red_r[r]+frm] = [np.nan for i in range(5)]\n",
    "logger.info('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fr in fracs:\n",
    "    for frm in fracs_model[fr]:\n",
    "        for r in reps[:2]:#[::-1]: \n",
    "            if red_r[r]+frm in k_fit.keys():\n",
    "                k_out = k_fit[red_r[r]+frm]\n",
    "                \n",
    "                logger.info('time_fit %s %s %s \\n' % (red_r[r], frm, [1/k for k in k_fit[red_r[r]+frm][:4]]))\n",
    "                \n",
    "                if not type(k_out[4])==float:#nan\n",
    "                    post = k_out[4]\n",
    "                    k_domain = np.geomspace(k_bound_lo, k_bound_hi, num=N_grid)\n",
    "\n",
    "                    sns.set(style=\"whitegrid\")\n",
    "                    fig, ax = plt.subplots(figsize=(4,4))#inches\n",
    "                    g = sns.lineplot(x=k_domain, y=post, color='b',\n",
    "                                  #sizes=[5],# linewidth=2,alpha=1,linestyle='-',\n",
    "                                  ax=ax,legend=False)\n",
    "                    plt.axvline(x=k_out[2], color='r', linestyle='-', linewidth=2)\n",
    "                    plt.axvline(x=k_out[0], color='g', linestyle='-', linewidth=2)\n",
    "                    plt.axvline(x=k_out[1], color='b', linestyle='-', linewidth=2)\n",
    "                    plt.axvline(x=k_out[3], color='r', linestyle='-', linewidth=2)\n",
    "                    plt.xlabel('k from ' + frm)\n",
    "                    plt.ylabel('posterior density function')\n",
    "                    plt.title(red_r[r]+ ' '+gene)\n",
    "                    g.set(xscale=\"log\") \n",
    "                    plt.xlim([k_out[2]/2,k_out[3]*1.5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asteval==0.9.23\n",
      "attrs==19.3.0\n",
      "backcall==0.1.0\n",
      "bleach==3.1.4\n",
      "certifi==2021.5.30\n",
      "charset-normalizer==2.0.1\n",
      "cycler==0.10.0\n",
      "decorator==4.4.2\n",
      "defusedxml==0.6.0\n",
      "docopt==0.6.2\n",
      "entrypoints==0.3\n",
      "future==0.18.2\n",
      "goatools==1.1.6\n",
      "gtfparse==1.2.1\n",
      "idna==3.2\n",
      "importlib-metadata==1.5.2\n",
      "ipykernel==5.2.0\n",
      "ipython==7.13.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.5.1\n",
      "jedi==0.16.0\n",
      "Jinja2==2.11.1\n",
      "joblib==1.1.0\n",
      "jsonschema==3.2.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==6.1.2\n",
      "jupyter-console==6.1.0\n",
      "jupyter-core==4.6.3\n",
      "kiwisolver==1.1.0\n",
      "llvmlite==0.36.0\n",
      "lmfit==1.0.2\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==3.2.1\n",
      "mistune==0.8.4\n",
      "mpmath==1.2.1\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.0.4\n",
      "networkx==2.4\n",
      "notebook==6.0.3\n",
      "numba==0.53.1\n",
      "numba-scipy==0.3.0\n",
      "numpy==1.16.5\n",
      "pandas==1.0.3\n",
      "pandocfilters==1.4.2\n",
      "parso==0.6.2\n",
      "patsy==0.5.2\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==7.0.0\n",
      "prometheus-client==0.7.1\n",
      "prompt-toolkit==3.0.4\n",
      "ptyprocess==0.6.0\n",
      "pydot==1.4.2\n",
      "Pygments==2.6.1\n",
      "pyparsing==2.4.6\n",
      "pyrsistent==0.16.0\n",
      "python-dateutil==2.8.1\n",
      "pytz==2019.3\n",
      "pyzmq==19.0.0\n",
      "qtconsole==4.7.2\n",
      "QtPy==1.9.0\n",
      "requests==2.26.0\n",
      "scikit-learn==1.0.1\n",
      "scipy==1.6.2\n",
      "seaborn==0.10.0\n",
      "Send2Trash==1.5.0\n",
      "six==1.14.0\n",
      "sklearn==0.0\n",
      "statsmodels==0.13.1\n",
      "sympy==1.8\n",
      "terminado==0.8.3\n",
      "testpath==0.4.4\n",
      "threadpoolctl==3.0.0\n",
      "torch==1.4.0\n",
      "torchvision==0.5.0\n",
      "tornado==6.0.4\n",
      "traitlets==4.3.3\n",
      "uncertainties==3.1.5\n",
      "urllib3==1.26.6\n",
      "virtualenv==16.7.4\n",
      "wcwidth==0.1.9\n",
      "webencodings==0.5.1\n",
      "wget==3.2\n",
      "widgetsnbextension==3.5.1\n",
      "xlrd==1.2.0\n",
      "XlsxWriter==3.0.2\n",
      "zipp==3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
