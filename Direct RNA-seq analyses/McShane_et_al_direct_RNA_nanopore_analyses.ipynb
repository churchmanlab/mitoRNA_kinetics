{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Author: Karine Choquet\n",
    "\n",
    "Date: August 7, 2021\n",
    "\n",
    "This script will analyze the mitochondrial transcriptome using direct RNA-seq data\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8048f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "\n",
    "import pybedtools\n",
    "from pybedtools import BedTool\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d293837",
   "metadata": {},
   "source": [
    "## Transcript abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5cfe6",
   "metadata": {},
   "source": [
    "### Read counts for whole gene and 100 or 200 nt windows at 3'-prime end of gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c201a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mito_transcripts_bedtool(annotation_df):\n",
    "\n",
    "    # make a set for all 3'SS coordinates\n",
    "    features = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # check if feature is an exon\n",
    "    for i in range(0,len(annotation_df)):\n",
    "        feature = annotation_df['feature'].iloc[i]   # feature\n",
    "        chrom = annotation_df['chrom'].iloc[i] # chromosome\n",
    " \n",
    "        if (feature == 'transcript') and (chrom == 'h_MT'):\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['info'].iloc[i].split(\";\")[4].split('\"')[1] # gene name\n",
    "            gene_biotype = annotation_df['info'].iloc[i].split(\";\")[6].split('\"')[1]\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "   \n",
    "            \n",
    "            # make a key that will represent intron coordinates\n",
    "            if gene_biotype != \"origin\":\n",
    "                features.append([str(chrom),str(start),str(end),str(gene),str(gene_biotype),str(strand)])\n",
    "\n",
    "    features_bedtool = BedTool(features)\n",
    "    return features_bedtool\n",
    "\n",
    "\n",
    "def get_mito_transcripts_bedtool_within_window(annotation_df, window):\n",
    "\n",
    "    # make a set for all 3'SS coordinates\n",
    "    features = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # check if feature is an exon\n",
    "    for i in range(0,len(annotation_df)):\n",
    "        feature = annotation_df['feature'].iloc[i]   # feature\n",
    "        chrom = annotation_df['chrom'].iloc[i] # chromosome\n",
    "        strand = annotation_df['strand'].iloc[i]\n",
    "\n",
    "        if (feature == 'transcript') and (chrom == 'h_MT'):\n",
    "            gene = annotation_df['info'].iloc[i].split(\";\")[4].split('\"')[1] # gene name\n",
    "            gene_biotype = annotation_df['info'].iloc[i].split(\";\")[6].split('\"')[1]\n",
    "            start = int(annotation_df['start'].iloc[i]) \n",
    "            end = int(annotation_df['end'].iloc[i])\n",
    "            \n",
    "            if strand == \"+\":\n",
    "                new_end = end\n",
    "                if start < end - window:\n",
    "                    new_start = end - window\n",
    "                elif start > end - window:\n",
    "                    new_start = start\n",
    "                    \n",
    "            elif strand == \"-\":\n",
    "                new_start = start\n",
    "                if end > start + window:\n",
    "                    new_end = start + window\n",
    "                elif end < start + window:\n",
    "                    new_end = end\n",
    "                    \n",
    "                            \n",
    "            # make a key that will represent intron coordinates\n",
    "            if gene_biotype != \"origin\":\n",
    "                features.append([str(chrom),str(new_start),str(new_end),str(gene),str(gene_biotype),str(strand)])\n",
    "\n",
    "    features_bedtool = BedTool(features)\n",
    "    return features_bedtool\n",
    "\n",
    "# function to create a dataframe with reads that span transcripts\n",
    "def get_transcript_intersect(transcript_df, bam_file):\n",
    "    # get reads that span 3' splice sites and convert to a dataframe\n",
    "    bedFile = bam_file.bam_to_bed(cigar=True, tag='NM') # convert bam file to bed file, keep cigar string and NM (edit distance) tag\n",
    "    intersect = bedFile.intersect(transcript_df, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    df = intersect.to_dataframe(names=['chr_aln', 'start_aln', 'end_aln', 'name_aln', 'qual_aln', \\\n",
    "                                           'strand_aln', 'cigar_aln', 'chr_transcript', 'start_transcript', \\\n",
    "                                           'end_transcript', 'name_gene', 'biotype_gene', 'strand_gene', 'count'], \\\n",
    "                               dtype={\"chr_aln\": str, \"start_aln\": int, \"end_aln\": int, \\\n",
    "                                     \"name_aln\": str, \"qual_aln\": int, \"strand_aln\": str, \\\n",
    "                                     \"cigar_aln\": str, \"chr_transcript\": str, \"start_transcript\": int, \\\n",
    "                                     \"end_transcript\": int, \"name_gene\": str, \\\n",
    "                                     \"biotype_gene\": str,\"strand_gene\": str, \"count\": int}) # convert to a dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "# parse every read that spans a transcript in the dataset to ensure that there are no large \"splicing\" events\n",
    "# that are likely artifacts\n",
    "# this is modelled after our splicing scripts for nuclear transcripts, which is why that nomenclature is used\n",
    "def parse_CIGAR(intersect_df, min_overlap):\n",
    "\n",
    "    read_list = []\n",
    "\n",
    "    for i in range(0,intersect_df.shape[0]):       \n",
    "\n",
    "        # define the read name\n",
    "        read_name = intersect_df['name_aln'].iloc[i]\n",
    "        gene_name = intersect_df['name_gene'].iloc[i]\n",
    "        chrom = intersect_df['chr_transcript'].iloc[i]\n",
    "        transcript_start = intersect_df['start_transcript'].iloc[i]\n",
    "        transcript_end = intersect_df['end_transcript'].iloc[i]\n",
    "        biotype = intersect_df['biotype_gene'].iloc[i]\n",
    "        strand = intersect_df['strand_gene'].iloc[i]\n",
    "        read_overlap = intersect_df['count'].iloc[i]\n",
    "        \n",
    "        # set variables for parsing the cigar string\n",
    "        pattern = re.compile('([MIDNSHPX=])')\n",
    "        Consumes_Query = [\"M\", \"I\", \"S\", \"=\", \"X\"]\n",
    "        Consumes_Reference = [\"M\", \"D\", \"N\", \"=\", \"X\"] \n",
    "        \n",
    "        # parse cigar string into a list of tuples for easy parsing\n",
    "        Sep_Values = pattern.split(intersect_df.cigar_aln[i])[:-1]\n",
    "        CigarPairs = list((Sep_Values[n:n+2] for n in range(0, len(Sep_Values), 2)))\n",
    "        \n",
    "        # get the 3' softclip length\n",
    "        if intersect_df.strand_aln[i]==\"+\":        \n",
    "            last=len(CigarPairs)\n",
    "            if(CigarPairs[last-1][1]=='S'):\n",
    "                clip_3prime=CigarPairs[last-1][0]\n",
    "            elif(CigarPairs[last-1][1]=='H'):\n",
    "                clip_3prime=CigarPairs[last-1][0]\n",
    "            elif(CigarPairs[last-1][1]!='S' or CigarPairs[last-1][1]!='H'):\n",
    "                clip_3prime=0\n",
    "                \n",
    "        if intersect_df.strand_aln[i]==\"-\":\n",
    "            if(CigarPairs[0][1]=='S'):\n",
    "                clip_3prime=CigarPairs[0][0]\n",
    "            elif(CigarPairs[0][1]=='H'):\n",
    "                clip_3prime=CigarPairs[0][0]\n",
    "            elif(CigarPairs[0][1]!='S' or CigarPairs[0][1]!='H'):\n",
    "                clip_3prime=0\n",
    "                \n",
    "        # get the 5' softclip length\n",
    "        if intersect_df.strand_aln[i]==\"+\":        \n",
    "            if(CigarPairs[0][1]=='S'):\n",
    "                clip_5prime=CigarPairs[0][0]\n",
    "            elif(CigarPairs[0][1]=='H'):\n",
    "                clip_5prime=CigarPairs[0][0]\n",
    "            elif(CigarPairs[0][1]!='S' or CigarPairs[0][1]!='H'):\n",
    "                clip_5prime=0\n",
    "                \n",
    "        if intersect_df.strand_aln[i]==\"-\":\n",
    "            last=len(CigarPairs)\n",
    "            if(CigarPairs[last-1][1]=='S'):\n",
    "                clip_5prime=CigarPairs[last-1][0]\n",
    "            elif(CigarPairs[last-1][1]=='H'):\n",
    "                clip_5prime=CigarPairs[last-1][0]\n",
    "            elif(CigarPairs[last-1][1]!='S' or CigarPairs[last-1][1]!='H'):\n",
    "                clip_5prime=0\n",
    "        \n",
    "        # set up variables for measuring the length of cigar string operators\n",
    "        CigarOp_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        start_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        end_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        intron_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        currentloc = int(intersect_df['start_aln'].iloc[i])\n",
    "        \n",
    "        \n",
    "        # go through list of cigar strings and grab splicing information\n",
    "        for cigar_Entry in CigarPairs:\n",
    "\n",
    "            op_Length = int(cigar_Entry[0]) # get length of cigar operator\n",
    "            cigarOp = cigar_Entry[1] # get type of cigar operator  \n",
    "            CigarOp_counts[cigarOp] += op_Length # add the cigar operator length to the counts dictionary\n",
    "            cigarOp_start=currentloc # get the starting coordinate of the cigar operator\n",
    "\n",
    "            if (cigarOp in Consumes_Reference):\n",
    "                currentloc=currentloc+op_Length # add the cigar operator length to the current location coordinate \n",
    "\n",
    "            cigarOp_end=currentloc # get the ending coordinate of the cigar operator\n",
    "\n",
    "            # gather information if the portion of the cigar string spans the designated intron start\n",
    "            if (cigarOp_start<transcript_start-min_overlap and cigarOp_end>=transcript_start-min_overlap):\n",
    "                if (cigarOp_end>=transcript_start+min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=cigarOp_end-(transcript_start-min_overlap)+1\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=transcript_start-min_overlap and cigarOp_end<transcript_start+min_overlap):\n",
    "                count=op_Length\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary       \n",
    "\n",
    "            elif (cigarOp_start<transcript_start+min_overlap and cigarOp_end>=transcript_start+min_overlap):\n",
    "                if (cigarOp_start<=transcript_start-min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=(transcript_start+min_overlap)-cigarOp_start-1\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary \n",
    "\n",
    "            # gather information if the portion of the cigar string is within the intron\n",
    "            if (cigarOp_start<transcript_start and cigarOp_end>=transcript_start):\n",
    "                if (cigarOp_end>=transcript_end):\n",
    "                    count=transcript_end-transcript_start\n",
    "                else:\n",
    "                    count=cigarOp_end-transcript_start\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=transcript_start and cigarOp_end<transcript_end):\n",
    "                count=op_Length\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start<transcript_end and cigarOp_end>=transcript_end):\n",
    "                if (cigarOp_start<=transcript_start):\n",
    "                    count=transcript_end-transcript_start\n",
    "                else:\n",
    "                    count=transcript_end-cigarOp_start\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary \n",
    "\n",
    "            # gather information if the portion of the cigar string spans the designated intron end\n",
    "            if (cigarOp_start<transcript_end-min_overlap and cigarOp_end>=transcript_end-min_overlap):\n",
    "                if (cigarOp_end>=transcript_end+min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=cigarOp_end-(transcript_end-min_overlap)\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=transcript_end-min_overlap and cigarOp_end<transcript_end+min_overlap):\n",
    "                count=op_Length\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start<transcript_end+min_overlap and cigarOp_end>=transcript_end+min_overlap):\n",
    "                if (cigarOp_start<=transcript_end-min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=(transcript_end+min_overlap)-cigarOp_start\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "        \n",
    "        \n",
    "        # Remove reads that have long portions that are \"spliced\" between two genes\n",
    "        if (end_counts['N']==0 and start_counts['N']==0):\n",
    "            if read_overlap > min_overlap:\n",
    "                \n",
    "                read_list.append([read_name, chrom, transcript_start, transcript_end, gene_name, biotype, strand, read_overlap, clip_5prime, clip_3prime])\n",
    "\n",
    "\n",
    "    read_df = pd.DataFrame(read_list)\n",
    "    read_df.columns = ['name_read','chrom','transcript_start','transcript_end','name_gene','biotype','strand','read_overlap','clip_5prime','clip_3prime']\n",
    "    \n",
    "    return read_df\n",
    "\n",
    "\n",
    "def get_gene_counts(bamFile):\n",
    "    \n",
    "    # Get reads intersecting transcripts, with different windows from the 3'-end\n",
    "    intersect_whole = get_transcript_intersect(hela_transcripts_whole_bedtool, bamFile)\n",
    "    intersect_100nt = get_transcript_intersect(hela_transcripts_100nt_window_bedtool, bamFile)\n",
    "    intersect_200nt = get_transcript_intersect(hela_transcripts_200nt_window_bedtool, bamFile)\n",
    "    \n",
    "    intersect_whole_filt = parse_CIGAR(intersect_whole, min_overlap)\n",
    "    intersect_100nt_filt = parse_CIGAR(intersect_100nt, min_overlap)\n",
    "    intersect_200nt_filt = parse_CIGAR(intersect_200nt, min_overlap)\n",
    "    \n",
    "    counts_whole = pd.DataFrame(intersect_whole_filt.drop_duplicates(subset=['name_read','name_gene']).groupby(['name_gene'])['name_read'].count()).reset_index()\n",
    "    counts_100nt = pd.DataFrame(intersect_100nt_filt.drop_duplicates(subset=['name_read','name_gene']).groupby(['name_gene'])['name_read'].count()).reset_index()\n",
    "    counts_200nt = pd.DataFrame(intersect_200nt_filt.drop_duplicates(subset=['name_read','name_gene']).groupby(['name_gene'])['name_read'].count()).reset_index()\n",
    "    \n",
    "    merged_df = counts_whole.merge(counts_100nt, on='name_gene').merge(counts_200nt, on='name_gene')\n",
    "    merged_df.columns = ['name_gene','count_whole','count_100nt_3prime','count_200nt_3prime']\n",
    "    \n",
    "    return(merged_df)\n",
    "\n",
    "\n",
    "def get_read_to_transcript_mapping_100nt(bamFile):\n",
    "    \n",
    "    intersect_100nt = get_transcript_intersect(hela_transcripts_100nt_window_bedtool, bamFile)\n",
    "    intersect_100nt_filt = parse_CIGAR(intersect_100nt, min_overlap)\n",
    "    \n",
    "    return(intersect_100nt_filt)\n",
    "\n",
    "def get_read_to_transcript_mapping_whole(bamFile):\n",
    "    \n",
    "    intersect_whole = get_transcript_intersect(hela_transcripts_whole_bedtool, bamFile)\n",
    "    intersect_whole_filt = parse_CIGAR(intersect_whole, min_overlap)\n",
    "    \n",
    "    return(intersect_whole_filt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38333dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karinechoquet/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "hela_gtf = pd.read_table('/path/to/annotations/Hela_ensGRCh38_h_MT_ncRNAs_allERCC_merge_MTmod.gtf', header=None, sep=\"\\t\",\n",
    "                        dtype={'chrom':str, 'build':str, 'feature':str, 'start':int, 'end':int, 'score1':int, 'strand':str, 'score2':int,\n",
    "                               'info':str})\n",
    "hela_gtf.columns = ['chrom','build','feature','start','end','score1','strand','score2','info']\n",
    "hela_gtf_mito = hela_gtf[hela_gtf['chrom']=='h_MT'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6854a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_bamFile = pybedtools.BedTool('/path/to/HeLa_EnrichedMito_directRNAseq_minimap2_sort.bam')\n",
    "tot1_bamFile = pybedtools.BedTool('/path/to/HeLa_WholeCell_directRNAseq_minimap2_sort.bam')\n",
    "tot2_bamFile = pybedtools.BedTool('/path/to/HeLa_WholeCell_rep2_directRNAseq_minimap2_sort.bam')\n",
    "tot3_bamFile = pybedtools.BedTool('/path/to/HeLa_totalRNA_3lig_minimap2_sort.bam')\n",
    "tot4_bamFile = pybedtools.BedTool('/path/to/HeLa_totalRNA_3lig_rep2_minimap2_sort.bam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d2aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all variables for analysis\n",
    "min_overlap = 25\n",
    "\n",
    "# make a dataframe of transcript coordinates\n",
    "hela_transcripts_whole_bedtool = get_mito_transcripts_bedtool(hela_gtf_mito)\n",
    "hela_transcripts_100nt_window_bedtool = get_mito_transcripts_bedtool_within_window(hela_gtf_mito, 100)\n",
    "hela_transcripts_200nt_window_bedtool = get_mito_transcripts_bedtool_within_window(hela_gtf_mito, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7fb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get read counts for each sample\n",
    "mito_gene_counts = get_gene_counts(mito_bamFile)\n",
    "tot1_gene_counts = get_gene_counts(tot1_bamFile)\n",
    "tot2_gene_counts = get_gene_counts(tot2_bamFile)\n",
    "tot3_gene_counts = get_gene_counts(tot3_bamFile)\n",
    "tot4_gene_counts = get_gene_counts(tot4_bamFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b9326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sample name\n",
    "mito_gene_counts['sample_name'] = 'mito_enriched_pA'\n",
    "tot1_gene_counts['sample_name'] = 'total_pA_rep1'\n",
    "tot2_gene_counts['sample_name'] = 'total_pA_rep2'\n",
    "tot3_gene_counts['sample_name'] = 'total_lig_rep1'\n",
    "tot4_gene_counts['sample_name'] = 'total_lig_rep2'\n",
    "\n",
    "# Write to file\n",
    "mito_gene_counts.to_csv(\"/path/to/mito_enriched_polyA_tailing_gene_counts.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot1_gene_counts.to_csv(\"/path/to/total_RNA_polyA_tailing_rep1_gene_counts.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot2_gene_counts.to_csv(\"/path/to/total_RNA_polyA_tailing_rep2_gene_counts.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot3_gene_counts.to_csv(\"/path/to/total_RNA_ligation_rep1_gene_counts.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot4_gene_counts.to_csv(\"/path/to/total_RNA_ligation_rep2_gene_counts.txt\", sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd1756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get read to transcript mapping for the 100 nt 3'prime window\n",
    "mito_transcript_map_100nt = get_read_to_transcript_mapping_100nt(mito_bamFile)\n",
    "tot1_transcript_map_100nt = get_read_to_transcript_mapping_100nt(tot1_bamFile)\n",
    "tot2_transcript_map_100nt = get_read_to_transcript_mapping_100nt(tot2_bamFile)\n",
    "tot3_transcript_map_100nt = get_read_to_transcript_mapping_100nt(tot3_bamFile)\n",
    "tot4_transcript_map_100nt = get_read_to_transcript_mapping_100nt(tot4_bamFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34aa083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get read to transcript mapping for the 100 nt 3'prime window\n",
    "mito_transcript_map_whole = get_read_to_transcript_mapping_whole(mito_bamFile)\n",
    "tot1_transcript_map_whole = get_read_to_transcript_mapping_whole(tot1_bamFile)\n",
    "tot2_transcript_map_whole = get_read_to_transcript_mapping_whole(tot2_bamFile)\n",
    "tot3_transcript_map_whole = get_read_to_transcript_mapping_whole(tot3_bamFile)\n",
    "tot4_transcript_map_whole = get_read_to_transcript_mapping_whole(tot4_bamFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K562 polyA+ samples\n",
    "K562_rep1_bamFile = pybedtools.BedTool(\"/path/to/K562_rep1_totalRNA_minimap2_sort.bam\")\n",
    "K562_rep2_bamFile = pybedtools.BedTool(\"/path/to/K562_rep2_totalRNA_minimap2_sort.bam\")\n",
    "\n",
    "K562_rep1_transcript_map_100nt = get_read_to_transcript_mapping_100nt(K562_rep1_bamFile)\n",
    "K562_rep2_transcript_map_100nt = get_read_to_transcript_mapping_100nt(K562_rep2_bamFile)\n",
    "\n",
    "K562_rep1_transcript_map_100nt.to_csv(\"/path/to/K562_rep1_transcript_map_100nt_3prime.txt\", sep=\"\\t\", header=True, index=False)\n",
    "K562_rep2_transcript_map_100nt.to_csv(\"/path/to/K562_rep2_transcript_map_100nt_3prime.txt\", sep=\"\\t\", header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18693f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Myoblasts polyA+ samples\n",
    "myo_D0_bamFile = pybedtools.BedTool(\"/path/to/myoblast_D0_polyA_directRNA_minimap2_sort.bam\")\n",
    "myo_D7_bamFile = pybedtools.BedTool(\"/path/to/myoblasts_D7_polyA_directRNA_minimap2_sort.bam\")\n",
    "\n",
    "myo_D0_transcript_map_100nt = get_read_to_transcript_mapping_100nt(myo_D0_bamFile)\n",
    "myo_D7_transcript_map_100nt = get_read_to_transcript_mapping_100nt(myo_D7_bamFile)\n",
    "\n",
    "myo_D0_transcript_map_100nt.to_csv(\"/path/to/myoblasts_D0_transcript_map_100nt_3prime.txt\", sep=\"\\t\", header=True, index=False)\n",
    "myo_D7_transcript_map_100nt.to_csv(\"/path/to/myoblasts_D7_transcript_map_100nt_3prime.txt\", sep=\"\\t\", header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "898e8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HeLa polyA+ sample\n",
    "HeLa_pA_bamFile = pybedtools.BedTool(\"/path/to/HeLa_total_polyA+_minimap2_sort.bam\")\n",
    "HeLa_transcript_map_100nt = get_read_to_transcript_mapping_100nt(HeLa_pA_bamFile)\n",
    "\n",
    "HeLa_transcript_map_100nt.to_csv(\"/path/to/HeLa_polyA+_transcript_map_100nt_3prime.txt\", sep=\"\\t\", header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe4ecc",
   "metadata": {},
   "source": [
    "### Correct abundance for polycistronic transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4b68b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mito_features_bedtool_for_read_ends_starts(annotation_df, polyA_window, TSS_window_pre, TSS_window_post, leader_window):\n",
    "\n",
    "    # make a set for all 3'SS coordinates\n",
    "    features = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # check if feature is an exon\n",
    "    for i in range(0,len(annotation_df)):\n",
    "        feature = annotation_df['feature'].iloc[i]   # feature\n",
    "        chrom = annotation_df['chrom'].iloc[i] # chromosome\n",
    " \n",
    "        if (feature == 'transcript') and (chrom == 'h_MT'):\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['info'].iloc[i].split(\";\")[4].split('\"')[1] # gene name\n",
    "            gene_biotype = annotation_df['info'].iloc[i].split(\";\")[6].split('\"')[1]\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "   \n",
    "            \n",
    "            if gene_biotype in ['protein_coding','Mt_rRNA','Mt_tRNA']:\n",
    "                if (strand=='+'):\n",
    "                    TSS_start = start - TSS_window_pre\n",
    "                    TSS_end = start + TSS_window_post\n",
    "                    \n",
    "                    polyA_start = end - polyA_window\n",
    "                    polyA_end = end + polyA_window\n",
    "                    \n",
    "                    gene_body_start = TSS_end\n",
    "                    gene_body_end = polyA_start\n",
    "                    \n",
    "                    leader_5prime_start = TSS_start - leader_window\n",
    "                    leader_5prime_end = TSS_start\n",
    "                \n",
    "                if (strand=='-'):\n",
    "                    TSS_start = end - TSS_window_post\n",
    "                    TSS_end = end + TSS_window_pre\n",
    "                    \n",
    "                    polyA_start = start - polyA_window\n",
    "                    polyA_end = start + polyA_window\n",
    "                    \n",
    "                    gene_body_start = polyA_end\n",
    "                    gene_body_end = TSS_start\n",
    "                    \n",
    "                    leader_5prime_start = TSS_end\n",
    "                    leader_5prime_end = TSS_end + leader_window\n",
    "\n",
    "                features.append([chrom,str(polyA_start),str(polyA_end),gene,'TES',strand,gene_biotype])\n",
    "                features.append([chrom,str(TSS_start),str(TSS_end),gene,'TSS',strand,gene_biotype])\n",
    "                features.append([chrom,gene_body_start,gene_body_end,gene,'gene_body',strand,gene_biotype])\n",
    "                features.append([chrom,leader_5prime_start,leader_5prime_end,gene,'leader_5prime',strand,gene_biotype])\n",
    "                \n",
    "            #elif gene_biotype == \"origin\":\n",
    "                #features.append([chrom,start,end,gene,'origin',strand,gene_biotype])\n",
    "              \n",
    "    #features.append(['h_MT',1,16569,'h_MT_+','intergenic','+','intergenic'])\n",
    "    #features.append(['h_MT',1,16569,'h_MT_-','intergenic','-','intergenic'])\n",
    "    features_bedtool = BedTool(features)\n",
    "    return features_bedtool\n",
    "\n",
    "\n",
    "\n",
    "def get_read_end_bedtool(bamFile):\n",
    "\n",
    "    bedFile = bamFile.bam_to_bed()\n",
    "    bedFile_df = bedFile.to_dataframe(dtype={'chrom':'str'})\n",
    "        \n",
    "    read_end = []\n",
    "        \n",
    "    for i in range(0,len(bedFile_df)):\n",
    "\n",
    "        chrom = str(bedFile_df['chrom'].iloc[i])\n",
    "        start = bedFile_df['start'].iloc[i]\n",
    "        end = bedFile_df['end'].iloc[i]\n",
    "        read = bedFile_df['name'].iloc[i]\n",
    "        score = bedFile_df['score'].iloc[i]\n",
    "        strand = bedFile_df['strand'].iloc[i]\n",
    "\n",
    "        if (strand == \"-\"):\n",
    "            pos_1 = start\n",
    "            pos_2 = start + 1\n",
    "\n",
    "        if (strand == \"+\"):\n",
    "            pos_1 = end - 1\n",
    "            pos_2 = end\n",
    "\n",
    "        read_end.append([chrom,str(pos_1),str(pos_2),read,str(score),strand])\n",
    "\n",
    "    read_end_bedtool = BedTool(read_end)\n",
    "    return read_end_bedtool\n",
    "\n",
    "\n",
    "\n",
    "def get_read_start_bedtool(bamFile):\n",
    "\n",
    "    bedFile = bamFile.bam_to_bed()\n",
    "    bedFile_df = bedFile.to_dataframe(dtype={'chrom':'str'})\n",
    "        \n",
    "    read_start = []\n",
    "        \n",
    "    for i in range(0,len(bedFile_df)):\n",
    "\n",
    "        chrom = str(bedFile_df['chrom'].iloc[i])\n",
    "        start = bedFile_df['start'].iloc[i]\n",
    "        end = bedFile_df['end'].iloc[i]\n",
    "        read = bedFile_df['name'].iloc[i]\n",
    "        score = bedFile_df['score'].iloc[i]\n",
    "        strand = bedFile_df['strand'].iloc[i]\n",
    "\n",
    "        if (strand == \"-\"):\n",
    "            pos_1 = end - 1\n",
    "            pos_2 = end\n",
    "\n",
    "        if (strand == \"+\"):\n",
    "            pos_1 = start\n",
    "            pos_2 = start + 1\n",
    "\n",
    "        read_start.append([chrom,str(pos_1),str(pos_2),read,str(score),strand])\n",
    "\n",
    "    read_start_bedtool = BedTool(read_start)\n",
    "    return read_start_bedtool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_intersect_read_ends_starts(read_ends, intron_info):\n",
    "\n",
    "    intersect = read_ends.intersect(intron_info, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    intersect_df = intersect.to_dataframe(names=['chrom_read', 'start_read', 'end_read', 'name_read', 'qual_read', \\\n",
    "                                           'strand_read', 'chr_feature', 'start_feature', \\\n",
    "                                           'end_feature', 'name_gene', 'name_feature', 'strand_feature', 'biotype_feature', 'count'], \\\n",
    "                               dtype={\"chrom_read\": str, \"start_read\": int, \"end_read\": int, \\\n",
    "                                     \"name_read\": str, \"qual_read\": int, \"strand_read\": str, \\\n",
    "                                    \"chr_feature\": str, \"start_feature\": int, \"end_feature\": int, \"name_gene\": str, \\\n",
    "                                     \"name_feature\": str,\"strand_feature\": str, \"biotype_feature\":str, \"count\": int}) # convert to a dataframe\n",
    "\n",
    "    return intersect_df\n",
    "\n",
    "\n",
    "\n",
    "def get_read_subcounts(bamFile, transcript_map, gene):\n",
    "    \n",
    "    # Get bedtool entries for that gene\n",
    "    hela_gtf_mito_sub = hela_gtf_mito[(hela_gtf_mito['info'].str.contains(gene))]\n",
    "    hela_mito_bedtool_sub = get_mito_features_bedtool_for_read_ends_starts(hela_gtf_mito_sub, polyA_window, TSS_window_pre, TSS_window_post, leader_window)\n",
    "    \n",
    "    # Get read ends and starts\n",
    "    read_ends = get_read_end_bedtool(bamFile)\n",
    "    read_starts = get_read_start_bedtool(bamFile)\n",
    "    \n",
    "    # Intersect with bedtool\n",
    "    intersect_ends = get_intersect_read_ends_starts(read_ends, hela_mito_bedtool_sub)\n",
    "    intersect_starts = get_intersect_read_ends_starts(read_starts, hela_mito_bedtool_sub)\n",
    "    \n",
    "    # Retrieve reads mapping to gene of interest from transcript map\n",
    "    transcript_map_sub = transcript_map[transcript_map['name_gene']==gene]\n",
    "\n",
    "    # Merge with read end and read start features\n",
    "    fields1 = ['name_read','name_gene','chrom','transcript_start','transcript_end']\n",
    "    fields2 = ['name_read','name_feature','name_gene']\n",
    "    intersect_map = transcript_map_sub[fields1].merge(intersect_ends[fields2], on=['name_read','name_gene'], how='left').rename(columns={'name_feature':'3prime_feature'}).merge(intersect_starts[fields2], on=['name_read','name_gene'], how='left').rename(columns={'name_feature':'5prime_feature'}).fillna(\"other\")\n",
    "    \n",
    "    # Count by features\n",
    "    subcounts = pd.DataFrame(intersect_map.groupby(['3prime_feature','5prime_feature'])['name_read'].count()).reset_index()\n",
    "\n",
    "    return(subcounts)\n",
    "\n",
    "\n",
    "\n",
    "def get_all_read_subcounts(bamFile, transcript_map_100nt, transcript_map_whole):\n",
    "    \n",
    "    subcounts_CO3_100nt = get_read_subcounts(bamFile, transcript_map_100nt, 'MT-CO3')\n",
    "    subcounts_CYB_100nt = get_read_subcounts(bamFile, transcript_map_100nt, 'MT-CYB')\n",
    "    \n",
    "    subcounts_CO3_whole = get_read_subcounts(bamFile, transcript_map_whole, 'MT-CO3')\n",
    "    subcounts_CYB_whole = get_read_subcounts(bamFile, transcript_map_whole, 'MT-CYB')\n",
    "    \n",
    "    subcounts_CO3_100nt['name_gene'] = 'MT-CO3'\n",
    "    subcounts_CYB_100nt['name_gene'] = 'MT-CYB'\n",
    "    subcounts_CO3_whole['name_gene'] = 'MT-CO3'\n",
    "    subcounts_CYB_whole['name_gene'] = 'MT-CYB'\n",
    "    \n",
    "    subcounts_100nt = pd.concat([subcounts_CO3_100nt,subcounts_CYB_100nt]).reset_index(drop=True)\n",
    "    subcounts_whole = pd.concat([subcounts_CO3_whole,subcounts_CYB_whole]).reset_index(drop=True)\n",
    "    \n",
    "    subcounts = pd.merge(subcounts_whole, subcounts_100nt, on=['name_gene','3prime_feature','5prime_feature'], how='left')[['name_gene','3prime_feature','5prime_feature','name_read_x','name_read_y']].fillna(0)\n",
    "    subcounts.columns = ['name_gene','3prime_feature','5prime_feature','count_whole','count_100nt_3prime']\n",
    "    \n",
    "    return(subcounts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95cc8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "polyA_window = 25\n",
    "TSS_window_post = 25\n",
    "TSS_window_pre = 0\n",
    "leader_window = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a6c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_subcounts = get_all_read_subcounts(mito_bamFile, mito_transcript_map_100nt, mito_transcript_map_whole)\n",
    "tot1_subcounts = get_all_read_subcounts(tot1_bamFile, tot1_transcript_map_100nt, tot1_transcript_map_whole)\n",
    "tot2_subcounts = get_all_read_subcounts(tot2_bamFile, tot2_transcript_map_100nt, tot2_transcript_map_whole)\n",
    "tot3_subcounts = get_all_read_subcounts(tot3_bamFile, tot3_transcript_map_100nt, tot3_transcript_map_whole)\n",
    "tot4_subcounts = get_all_read_subcounts(tot4_bamFile, tot4_transcript_map_100nt, tot4_transcript_map_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b85dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "mito_subcounts.to_csv(\"/path/to/mito_enriched_polyA_tailing_subcounts_MT-CO3_MT-CYB.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot1_subcounts.to_csv(\"/path/to/total_RNA_polyA_tailing_rep1_subcounts_MT-CO3_MT-CYB.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot2_subcounts.to_csv(\"/path/to/total_RNA_polyA_tailing_rep2_subcounts_MT-CO3_MT-CYB.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot3_subcounts.to_csv(\"/path/to/total_RNA_ligation_rep1_subcounts_MT-CO3_MT-CYB.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot4_subcounts.to_csv(\"/path/to/total_RNA_ligation_rep2_subcounts_MT-CO3_MT-CYB.txt\", sep=\"\\t\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1dd94",
   "metadata": {},
   "source": [
    "## Read ends for modelling transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb92ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mito_features_bedtool(annotation_df, polyA_window):\n",
    "\n",
    "    # make a set for all 3'SS coordinates\n",
    "    features = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # check if feature is an exon\n",
    "    for i in range(0,len(annotation_df)):\n",
    "        feature = annotation_df['feature'].iloc[i]   # feature\n",
    "        chrom = annotation_df['chrom'].iloc[i] # chromosome\n",
    " \n",
    "        if (feature == 'transcript') and (chrom == 'h_MT'):\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['info'].iloc[i].split(\";\")[4].split('\"')[1] # gene name\n",
    "            gene_biotype = annotation_df['info'].iloc[i].split(\";\")[6].split('\"')[1]\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "   \n",
    "            \n",
    "            if gene_biotype in ['protein_coding','Mt_rRNA','Mt_tRNA']:\n",
    "                if (strand=='+'):\n",
    "                    polyA_start = end - polyA_window\n",
    "                    polyA_end = end + polyA_window\n",
    "                \n",
    "                if (strand=='-'):\n",
    "                    polyA_start = start - polyA_window\n",
    "                    polyA_end = start + polyA_window\n",
    "\n",
    "                features.append([chrom,str(polyA_start),str(polyA_end),gene,'3prime_end',strand,gene_biotype])\n",
    "                features.append([chrom,start,end,gene,'gene_body',strand,gene_biotype])\n",
    "                \n",
    "            elif gene_biotype == \"origin\":\n",
    "                features.append([chrom,start,end,gene,'origin',strand,gene_biotype])\n",
    "              \n",
    "    features.append(['h_MT',1,16569,'h_MT_+','intergenic','+','intergenic'])\n",
    "    features.append(['h_MT',1,16569,'h_MT_-','intergenic','-','intergenic'])\n",
    "    features_bedtool = BedTool(features)\n",
    "    return features_bedtool\n",
    "\n",
    "\n",
    "\n",
    "def get_read_end_bedtool(bamFile):\n",
    "\n",
    "    bedFile = bamFile.bam_to_bed()\n",
    "    bedFile_df = bedFile.to_dataframe()\n",
    "        \n",
    "    read_end = []\n",
    "        \n",
    "    for i in range(0,len(bedFile_df)):\n",
    "\n",
    "        chrom = str(bedFile_df['chrom'].iloc[i])\n",
    "        start = bedFile_df['start'].iloc[i]\n",
    "        end = bedFile_df['end'].iloc[i]\n",
    "        read = bedFile_df['name'].iloc[i]\n",
    "        score = bedFile_df['score'].iloc[i]\n",
    "        strand = bedFile_df['strand'].iloc[i]\n",
    "\n",
    "        if (strand == \"-\"):\n",
    "            pos_1 = start\n",
    "            pos_2 = start + 1\n",
    "\n",
    "        if (strand == \"+\"):\n",
    "            pos_1 = end - 1\n",
    "            pos_2 = end\n",
    "\n",
    "        read_end.append([chrom,str(pos_1),str(pos_2),read,str(score),strand])\n",
    "\n",
    "    read_end_bedtool = BedTool(read_end)\n",
    "    return read_end_bedtool\n",
    "\n",
    "\n",
    "\n",
    "def get_intersect(read_ends, intron_info):\n",
    "\n",
    "    intersect = read_ends.intersect(intron_info, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    intersect_df = intersect.to_dataframe(names=['chrom_read', 'start_read', 'end_read', 'name_read', 'qual_read', \\\n",
    "                                           'strand_read', 'chr_feature', 'start_feature', \\\n",
    "                                           'end_feature', 'name_gene', 'name_feature', 'strand_feature', 'biotype_feature', 'count'], \\\n",
    "                               dtype={\"chrom_read\": str, \"start_read\": int, \"end_read\": int, \\\n",
    "                                     \"name_read\": str, \"qual_read\": int, \"strand_read\": str, \\\n",
    "                                    \"chr_feature\": str, \"start_feature\": int, \"end_feature\": int, \"name_gene\": str, \\\n",
    "                                     \"name_feature\": str,\"strand_feature\": str, \"biotype_feature\":str, \"count\": int}) # convert to a dataframe\n",
    "\n",
    "    return intersect_df\n",
    "\n",
    "\n",
    "\n",
    "def get_read_end_mapping(intersect_df):\n",
    "\n",
    "    read_ends = {}\n",
    "\n",
    "    for i in range(0,len(intersect_df)):\n",
    "\n",
    "        # get read name and feature type\n",
    "        read = intersect_df['name_read'].iloc[i]\n",
    "        feature = intersect_df['name_feature'].iloc[i]\n",
    "        biotype = intersect_df['biotype_feature'].iloc[i]\n",
    "        strand = intersect_df['strand_read'].iloc[i]\n",
    "        \n",
    "        feature_type = feature + \"__\" + biotype + \",\" + strand\n",
    "\n",
    "        # check if read name is in the dictionary, if not save it\n",
    "        if read not in read_ends.keys():\n",
    "\n",
    "            # make a new dictionary for the read and end mapping info\n",
    "            read_ends[read] = [feature_type]\n",
    "\n",
    "        # check if read name is in the dictionary, if not save it\n",
    "        if read in read_ends.keys():\n",
    "\n",
    "            # if end mapping info is different, append it to the dictionary\n",
    "            if (feature_type not in read_ends[read]):\n",
    "                read_ends[read].append(feature_type)\n",
    "    \n",
    "    return read_ends\n",
    "\n",
    "\n",
    "\n",
    "def get_read_end_stats(read_ends):\n",
    "    \n",
    "    read_features = []\n",
    "\n",
    "    for k, v in read_ends.items():\n",
    "\n",
    "        if (len(v) == 1):\n",
    "            read_features.append([k,v[0]])\n",
    "\n",
    "        if (len(v) > 1):\n",
    "            if (\"3prime_end__Mt_rRNA,+\" in v):\n",
    "                read_features.append([k,\"3prime_end__Mt_rRNA,+\"])\n",
    "                \n",
    "            elif (\"3prime_end__Mt_tRNA,+\" in v):\n",
    "                read_features.append([k,\"3prime_end__Mt_tRNA,+\"])\n",
    "                \n",
    "            elif (\"3prime_end__protein_coding,+\" in v):\n",
    "                read_features.append([k,\"3prime_end__protein_coding,+\"])\n",
    "                \n",
    "            elif (\"3prime_end__Mt_rRNA,-\" in v):\n",
    "                read_features.append([k,\"3prime_end__Mt_rRNA,-\"])\n",
    "                \n",
    "            elif (\"3prime_end__Mt_tRNA,-\" in v):\n",
    "                read_features.append([k,\"3prime_end__Mt_tRNA,-\"])\n",
    "                \n",
    "            elif (\"3prime_end__protein_coding,-\" in v):\n",
    "                read_features.append([k,\"3prime_end__protein_coding,-\"])\n",
    "                \n",
    "            elif (\"gene_body__Mt_rRNA,+\" in v):\n",
    "                read_features.append([k,\"gene_body__Mt_rRNA,+\"])\n",
    "                \n",
    "            elif (\"gene_body__Mt_tRNA,+\" in v):\n",
    "                read_features.append([k,\"gene_body__Mt_tRNA,+\"])\n",
    "                \n",
    "            elif (\"gene_body__protein_coding,+\" in v):\n",
    "                read_features.append([k,\"gene_body__protein_coding,+\"])\n",
    "                \n",
    "            elif (\"gene_body__Mt_rRNA,-\" in v):\n",
    "                read_features.append([k,\"gene_body__Mt_rRNA,-\"])\n",
    "                \n",
    "            elif (\"gene_body__Mt_tRNA,-\" in v):\n",
    "                read_features.append([k,\"gene_body__Mt_tRNA,-\"])\n",
    "                \n",
    "            elif (\"gene_body__protein_coding,-\" in v):\n",
    "                read_features.append([k,\"gene_body__protein_coding,-\"])\n",
    "            else:\n",
    "                read_features.append([k,\"undetermined\"])\n",
    "\n",
    "    read_features_df = pd.DataFrame(read_features)\n",
    "    read_features_df.columns = ['read','end_feature']\n",
    "    \n",
    "    return read_features_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7810bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "polyA_window = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40581b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hela_gtf_mito = hela_gtf[hela_gtf['chrom']=='h_MT'].reset_index(drop=True)\n",
    "hela_mito_bedtool = get_mito_features_bedtool(hela_gtf_mito, polyA_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e322737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karinechoquet/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# get read ends and turn into a bedtool for intersecting \n",
    "mito_read_ends = get_read_end_bedtool(mito_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "mito_intersect = get_intersect(mito_read_ends, hela_mito_bedtool)\n",
    "\n",
    "# get read ends dictionary\n",
    "mito_read_end_mapping = get_read_end_mapping(mito_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "mito_read_end_stats = get_read_end_stats(mito_read_end_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "5ece8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karinechoquet/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# get read ends and turn into a bedtool for intersecting \n",
    "tot1_read_ends = get_read_end_bedtool(tot1_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "tot1_intersect = get_intersect(tot1_read_ends, hela_mito_bedtool)\n",
    "\n",
    "# get read ends dictionary\n",
    "tot1_read_end_mapping = get_read_end_mapping(tot1_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "tot1_read_end_stats = get_read_end_stats(tot1_read_end_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "3e102eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karinechoquet/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# get read ends and turn into a bedtool for intersecting \n",
    "tot2_read_ends = get_read_end_bedtool(tot2_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "tot2_intersect = get_intersect(tot2_read_ends, hela_mito_bedtool)\n",
    "\n",
    "# get read ends dictionary\n",
    "tot2_read_end_mapping = get_read_end_mapping(tot2_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "tot2_read_end_stats = get_read_end_stats(tot2_read_end_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9c260302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karinechoquet/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# get read ends and turn into a bedtool for intersecting \n",
    "tot3_read_ends = get_read_end_bedtool(tot3_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "tot3_intersect = get_intersect(tot3_read_ends, hela_mito_bedtool)\n",
    "\n",
    "# get read ends dictionary\n",
    "tot3_read_end_mapping = get_read_end_mapping(tot3_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "tot3_read_end_stats = get_read_end_stats(tot3_read_end_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "8a7f08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get read ends and turn into a bedtool for intersecting \n",
    "tot4_read_ends = get_read_end_bedtool(tot4_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "tot4_intersect = get_intersect(tot4_read_ends, hela_mito_bedtool)\n",
    "\n",
    "# get read ends dictionary\n",
    "tot4_read_end_mapping = get_read_end_mapping(tot4_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "tot4_read_end_stats = get_read_end_stats(tot4_read_end_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "cf30c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_read_ends_df = mito_read_ends.to_dataframe()\n",
    "mito_read_ends_df_MT = mito_read_ends_df[mito_read_ends_df['chrom']=='h_MT'].reset_index(drop=True)\n",
    "mito_read_ends_df_MT.to_csv('/path/to/mito_read_ends_coordinates.txt', sep='\\t', index=False, header=True)\n",
    "\n",
    "tot1_read_ends_df = tot1_read_ends.to_dataframe()\n",
    "tot1_read_ends_df_MT = tot1_read_ends_df[tot1_read_ends_df['chrom']=='h_MT'].reset_index(drop=True)\n",
    "tot1_read_ends_df_MT.to_csv('/path/to/tot1_read_ends_coordinates.txt', sep='\\t', index=False, header=True)\n",
    "\n",
    "tot2_read_ends_df = tot2_read_ends.to_dataframe()\n",
    "tot2_read_ends_df_MT = tot2_read_ends_df[tot2_read_ends_df['chrom']=='h_MT'].reset_index(drop=True)\n",
    "tot2_read_ends_df_MT.to_csv('/path/to/tot2_read_ends_coordinates.txt', sep='\\t', index=False, header=True)\n",
    "\n",
    "tot3_read_ends_df = tot3_read_ends.to_dataframe()\n",
    "tot3_read_ends_df_MT = tot3_read_ends_df[tot3_read_ends_df['chrom']=='h_MT'].reset_index(drop=True)\n",
    "tot3_read_ends_df_MT.to_csv('/path/to/tot3_read_ends_coordinates.txt', sep='\\t', index=False, header=True)\n",
    "\n",
    "tot4_read_ends_df = tot4_read_ends.to_dataframe()\n",
    "tot4_read_ends_df_MT = tot4_read_ends_df[tot4_read_ends_df['chrom']=='h_MT'].reset_index(drop=True)\n",
    "tot4_read_ends_df_MT.to_csv('/path/to/tot4_read_ends_coordinates.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b8647325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "mito_read_end_stats.to_csv(\"/path/to/mito_enriched_polyA_tailing_read_end_features.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot1_read_end_stats.to_csv(\"/path/to/total_RNA_polyA_tailing_rep1_read_end_features.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot2_read_end_stats.to_csv(\"/path/to/total_RNA_polyA_tailing_rep2_read_end_features.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot3_read_end_stats.to_csv(\"/path/to/total_RNA_ligation_rep1_read_end_features.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot4_read_end_stats.to_csv(\"/path/to/total_RNA_ligation_rep2_read_end_features.txt\", sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c6896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee281be3",
   "metadata": {},
   "source": [
    "## Poly(A) tails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628c8d5",
   "metadata": {},
   "source": [
    "### 3'-end ligation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77214d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get processing status (computed on HPC cluster)\n",
    "tot3_process_df = pd.read_table(\"/path/to/total_RNA_ligation_rep1_read_processing_status.txt\")\n",
    "tot4_process_df = pd.read_table(\"/path/to/total_RNA_ligation_rep2_read_processing_status.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a186e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot3_nano_df = pd.read_table(\"/path/to/total_RNA_ligation_rep1.polyA_estimates.tsv\",\n",
    "                            dtype={'readname':str, 'contig':str, 'position':int, 'leader_start':int, 'adapter_start':int, 'polya_start':int,\n",
    "                               'transcript_start':int, 'read_rate':float, 'polya_length':float, 'qc_tag':str})\n",
    "tot4_nano_df = pd.read_table(\"/path/to/total_RNA_ligation_rep2.polyA_estimates.tsv\",\n",
    "                            dtype={'readname':str, 'contig':str, 'position':int, 'leader_start':int, 'adapter_start':int, 'polya_start':int,\n",
    "                               'transcript_start':int, 'read_rate':float, 'polya_length':float, 'qc_tag':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c32949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter reads\n",
    "tot3_pass_df = tot3_nano_df[tot3_nano_df['qc_tag'].isin(['PASS','NOREGION','ADAPTER'])].reset_index(drop=True)\n",
    "tot3_pass_df = tot3_pass_df.merge(tot3_transcript_map_100nt[['name_read','name_gene']], left_on='readname', right_on='name_read')\n",
    "\n",
    "# Add a category for poly(A) tail\n",
    "tot3_pass_df['polyA_tail'] = 'other'\n",
    "tot3_pass_df.loc[(tot3_pass_df['qc_tag'].isin(['PASS','ADAPTER'])),'polyA_tail'] = 'pA'\n",
    "tot3_pass_df.loc[(tot3_pass_df['qc_tag'] == 'NOREGION'),'polyA_tail'] = 'no_pA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7430724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter reads\n",
    "tot4_pass_df = tot4_nano_df[tot4_nano_df['qc_tag'].isin(['PASS','NOREGION','ADAPTER'])].reset_index(drop=True)\n",
    "tot4_pass_df = tot4_pass_df.merge(tot4_transcript_map_100nt[['name_read','name_gene']], left_on='readname', right_on='name_read')\n",
    "\n",
    "# Add a category for poly(A) tail\n",
    "tot4_pass_df['polyA_tail'] = 'other'\n",
    "tot4_pass_df.loc[(tot4_pass_df['qc_tag'].isin(['PASS','ADAPTER'])),'polyA_tail'] = 'pA'\n",
    "tot4_pass_df.loc[(tot4_pass_df['qc_tag'] == 'NOREGION'),'polyA_tail'] = 'no_pA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8515ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e46302",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot3_pass_df_process = tot3_pass_df.merge(tot3_process_df[['read','gene_name','category_3prime']], left_on=['name_read','name_gene'], right_on=['read','gene_name'])\n",
    "tot4_pass_df_process = tot4_pass_df.merge(tot4_process_df[['read','gene_name','category_3prime']], left_on=['name_read','name_gene'], right_on=['read','gene_name'])\n",
    "\n",
    "tot3_pass_df_process['category2'] = tot3_pass_df_process['category_3prime'] + ',' + tot3_pass_df_process['polyA_tail']\n",
    "tot4_pass_df_process['category2'] = tot4_pass_df_process['category_3prime'] + ',' + tot4_pass_df_process['polyA_tail']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8784d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count reads with/without pA tail\n",
    "tot3_nano_counts = pd.DataFrame(tot3_pass_df_process.groupby(['name_gene','category2'])['readname'].count()).reset_index().rename(columns={'readname':'read_count'})\n",
    "tot3_nano_counts_piv = tot3_nano_counts.pivot(index='name_gene',columns='category2',values='read_count').reset_index().rename(columns={'yes':'with_polyA','no':'no_polyA'}).fillna(0)\n",
    "\n",
    "tot4_nano_counts = pd.DataFrame(tot4_pass_df_process.groupby(['name_gene','category2'])['readname'].count()).reset_index().rename(columns={'readname':'read_count'})\n",
    "tot4_nano_counts_piv = tot4_nano_counts.pivot(index='name_gene',columns='category2',values='read_count').reset_index().rename(columns={'yes':'with_polyA','no':'no_polyA'}).fillna(0)\n",
    "\n",
    "\n",
    "tot3_nano_counts_piv_filt = tot3_nano_counts_piv[(tot3_nano_counts_piv['processed_3prime,no_pA']>=5) | (tot3_nano_counts_piv['processed_3prime,pA']>=5)].reset_index(drop=True)\n",
    "tot4_nano_counts_piv_filt = tot4_nano_counts_piv[(tot4_nano_counts_piv['processed_3prime,no_pA']>=5) | (tot4_nano_counts_piv['processed_3prime,pA']>=5)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "tot3_nano_counts_piv_filt.to_csv(\"/path/to/total_RNA_ligation_rep1_with_or_without_polyA_counts.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot4_nano_counts_piv_filt.to_csv(\"/path/to/total_RNA_ligation_rep2_with_or_without_polyA_counts.txt\", sep=\"\\t\", header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "272caceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for reads with pA tail\n",
    "tot3_pA_df = tot3_pass_df[tot3_pass_df['polyA_tail']=='pA'][['name_read','name_gene','polya_length']].reset_index(drop=True)\n",
    "tot4_pA_df = tot4_pass_df[tot4_pass_df['polyA_tail']=='pA'][['name_read','name_gene','polya_length']].reset_index(drop=True)\n",
    "\n",
    "tot3_pA_df.to_csv(\"/path/to/total_RNA_ligation_rep1_polyA_length.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot4_pA_df.to_csv(\"/path/to/total_RNA_ligation_rep2_polyA_length.txt\", sep=\"\\t\", header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2f00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "810e1eee",
   "metadata": {},
   "source": [
    "## Reads for screenshot figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f44aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "polyA_window = 25\n",
    "TSS_window_post = 25\n",
    "TSS_window_pre = 0\n",
    "leader_window = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97c3ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot1_transcript_map_whole_CO1 = tot1_transcript_map_whole[tot1_transcript_map_whole['name_gene']=='MT-CO1'].reset_index(drop=True)\n",
    "tot1_transcript_map_whole_CO1_sub = tot1_transcript_map_whole_CO1.sample(100)\n",
    "\n",
    "\n",
    "tot1_transcript_map_whole_ND1 = tot1_transcript_map_whole[tot1_transcript_map_whole['name_gene']=='MT-ND1'].reset_index(drop=True)\n",
    "tot1_transcript_map_whole_ND1_sub = tot1_transcript_map_whole_ND1.sample(50)\n",
    "\n",
    "\n",
    "tot1_transcript_map_whole_CO3 = tot1_transcript_map_whole[(tot1_transcript_map_whole['name_gene']=='MT-CO3') | (tot1_transcript_map_whole['name_gene']=='MT-ATP8-6')].reset_index(drop=True)\n",
    "tot1_transcript_map_whole_CO3_sub = tot1_transcript_map_whole_CO3.sample(100)\n",
    "\n",
    "tot1_transcript_map_whole_CO1_sub['name_read'].to_csv(\"/path/to/reads_for_screenshots_CO1_v1.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot1_transcript_map_whole_ND1_sub['name_read'].to_csv(\"/path/to/reads_for_screenshots_ND1_v1.txt\", sep=\"\\t\", header=True, index=False)\n",
    "tot1_transcript_map_whole_CO3_sub['name_read'].to_csv(\"/path/to/reads_for_screenshots_CO3_ATP8-6_v1.txt\", sep=\"\\t\", header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c45a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
